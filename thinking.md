# Размышления над задачей

## Знакомство с таблицей user

Размеры: 3910×4, поля (uid, source, region, cost).

uid:
  Возрастающее целое число от 1 до кол-ва пользователей, первичный ключ.

source:
  Видимо, источник привлечения пользователя. Принимает одно из значений: 
  (cpc_adwords, cpc_direct, seo, smm). Стоимость разных источников мало
  отличается, боксплоты и вайолины очень похожи.  Есть отличия по регионам.

  ```
  > ggplot(user, aes(source, cost)) + geom_boxplot()
  > ggplot(user, aes(source, cost)) + geom_violin()
  ```

 Количество пользователей, привлечённых разными способами:
 
 | Способ привлечения | Цена |
 |:-------------------|-----:|
 | cpc_adwords        | 958  |
 | cpc_direct         | 922  |
 | seo                | 1016 |
 | smm                | 1014 |

region:
  Регион пользователя. Есть 6 регионов, количество пользователей в них близко:

  | регион            | #users |
  |:------------------|-------:|
  | ekb               |  609   |
  | moscow            |  645   |
  | orel              |  687   |
  | spb               |  664   |
  | vladimir          |  619   |
  | volgograd         |  686   |

cost:
  По всей видимости, стоимость привлечения пользователя. В среднем стоимость привлечения незначительно
  изменяется от региона к региону, но есть заметные отличия по способам привлечения.  Медианная стоимость
  привлечения пользователя в разрезе способов привлечения и регионов:

|region       |  cpc_adwords |  cpc_direct | seo   | smm
|:------------|:-------------|:------------|:------|:--------------
|       ekb   |   343.5      |   354       | 365   | 358
|    moscow   |   359        |   350       | 366   | 337.5
|      orel   |   359.5      |   346.5     | 310.5 | 345
|       spb   |   356.5      |   349       | 339   | 370
|  vladimir   |   358        |   372       | 332   | 358
| volgograd   |   340        |   341       | 347.5 | 353


## Знакомство с таблицей log

Размыры: 35775×4, поля (uid, date, event_type, sum), где uid ссылка на идентификатор пользователя,
date в формате YYYY-MM-DD, event_type может быть "(visit|purchase)" и sum либо сумма покупки, либо NA.

Первичного ключа в таблице нет.

Диапазон дат: 1 января — 5 марта 2014

```
R> summary(log$date)
        Min.      1st Qu.       Median         Mean      3rd Qu.         Max. 
"2014-01-01" "2014-01-21" "2014-02-05" "2014-02-03" "2014-02-19" "2014-03-05" 
```

Даты в логе не отсортированы (довольно странно для лога :) )

Проверяю, нужна ли мне вообще колонка 'event_type'

```
dgolub=> select * from prj1.log where event_type='visit' and sum is not null;
 uid | date | event_type | sum 
-----+------+------------+-----
(0 rows)
```

Понятно, таких нет.  А покупка без суммы?

```
dgolub=> select * from prj1.log where event_type='purchase' and sum is null;
 uid | date | event_type | sum 
-----+------+------------+-----
(0 rows)
```

ОК, при визите не покупаем, при покупке всегда платим. Можно event type не
держать в таблице.

Юнит-экономику можно считать по месяцам или по неделям, для этого есть смысл
завести отдельные колонки в базе данных с номером месяца и номером недели.

# Преобразования таблиц

## Первый визит пользователя

Для когортных расчётов нужно знать, когда пользователь пришёл первый раз, это
можно сделать, найдя минимальную дату его визита.

```{sql}
select u.uid, min(l.date)
  from prj1.user as u
  left join prj1.log as l
  on u.uid=l.uid group by u.uid 
  order by u.uid ;
```

Забавно, что для некоторых пользвателей визитов и покупок нет вообще.  Мы их
привлекли, этим всё и ограничилось.

Для когортного анализа полезны номера месяцев и недель. Можно нарезать эти
промежутки с помощью функций date_trunc (то есть привести к первой дате
интервала) или преобразовать в номер месяца (недели).  Нужную информацию можно
внести прямо в таблицу `log`.

```
select date, date_part('month', date) as month, date_part('week', date) as week from prj1.log;
```

Добавлю колонки month & week. Следующим действием поставлю их после даты.

```
dgolub=> alter table prj1.log add column month int, add column week int;
ALTER TABLE

dgolub=> select * from prj1.log limit 5;

 uid |    date    | event_type | sum  | month | week 
-----+------------+------------+------+-------+------
 256 | 2014-01-02 | visit      |      |       |     
 256 | 2014-01-04 | visit      |      |       |     
 256 | 2014-01-04 | purchase   | 1587 |       |     
 268 | 2014-01-03 | visit      |      |       |     
 268 | 2014-01-01 | visit      |      |       |     
(5 rows)
```

Заполняю колонки с месяцем и неделей.

```
dgolub=> update prj1.log set week = date_part('week', date);
UPDATE 35775

dgolub=> select * from prj1.log limit 10 offset 124;

 uid |    date    | event_type | sum | month | week 
-----+------------+------------+-----+-------+------
  34 | 2014-01-03 | visit      |     |     1 |    1
  34 | 2014-01-05 | visit      |     |     1 |    1
  34 | 2014-01-06 | visit      |     |     1 |    2
  34 | 2014-01-03 | visit      |     |     1 |    1
  36 | 2014-01-07 | visit      |     |     1 |    2
  36 | 2014-01-02 | visit      |     |     1 |    1
  31 | 2014-01-05 | visit      |     |     1 |    1
  31 | 2014-01-05 | purchase   | 796 |     1 |    1
  31 | 2014-01-03 | visit      |     |     1 |    1
  31 | 2014-01-06 | visit      |     |     1 |    2
```

Создаю таблицу и начинаю заполнять юнит-экономику по месяцам и по неделям. У
нас 2 месяца и 10 недель (первая и последняя недели неполные, и оба месяца
аномальных: январь с новогодними каникулами и февраль короткий).

Заполнение юнит-экономики упёрлось в стоимость привлечения, для чего нужно понять,
когда этот пользователь впервые пришёл на сайт.  У нас есть данные визитов, но нужно
соединить их с таблицей пользователей.

Добавляю в таблицу пользователей поля для первого контакта, месяца первого контакта 
и номера недели первого контакта.

```
dgolub=> alter table prj1.user add column first_visit date, add column start_mon int, add column start_week int;
ALTER TABLE

dgolub=> select * from prj1.user limit 5;

 uid |    source    |   region   | cost | first_visit | start_mon | start_week 
-----+--------------+------------+------+-------------+-----------+------------
   1 | seo          | vladimir   |  321 |             |           |           
   2 | cpc_direct   | vladimir   |  228 |             |           |           
   3 | smm          | vladimir   |  436 |             |           |           
   4 | smm          | vladimir   |  464 |             |           |           
   5 | cpc_direct   | ekb        |  269 |             |           |           
(5 rows)

```

Как заполнить эти поля? Нужно слить две таблицы и сделать update в одной из них.
На [StackOverflow](https://stackoverflow.com/questions/1293330/how-can-i-do-an-update-statement-with-join-in-sql)
написано, что для PostgreSQL действует синтаксис:

```
update ud
  set ud.assid = s.assid
from sale s 
where ud.id = s.udid;
```

Для нашего случая это превращается в довольно запутанную форму, поскольку нужно ещё считать агрегатные
функции. Проще всего создать временную таблицу и удалить её после работы.

Сначала пытался создать таблицу в той же схеме, но это невозможно:

```
dgolub=> create temp table prj1.first_visit as 
	select u.uid, min(l.date) from prj1.user as u inner join prj1.log as l on u.uid=l.uid 
	group by u.uid order by u.uid ;
ERROR:  cannot create temporary relation in non-temporary schema
```

Правильная команда создаёт таблицу в схеме `public`.

```
create temp table first_visit as 
	select u.uid, min(l.date) 
	from 
		prj1.user as u 
		inner join 
		prj1.log as l 
		on u.uid=l.uid 
	group by u.uid
	order by u.uid ;
SELECT 3637
```

Я бездумно скопировал сюда пример, котоый был рассмотрен выше — с LEFT JOIN, а тут таблица `user`
и вовсе не нужна, все нужные данные уже в таблице `log`.  То же самое выдаёт команда попроще:

Таблица напрасно названа `first_visit`, у нас уже есть поле с таким именем.  Дропаю её и
создаю снова.

```
dgolub=> ... select uid, min(date) from prj1.log group by uid order by uid;
 uid |    min     
-----+------------
   1 | 2014-01-01
   2 | 2014-01-04
   3 | 2014-01-05
...
```

Таблица наследует типы полей от родительских, они не задаются.

```
dgolub=> \d first_visit

           Table "pg_temp_3.first_visit"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 uid    | integer |           |          | 
 min    | date    |           |          | 
```

Содержимое таблицы:

```
dgolub=> select * from first_visit limit 10;
 uid |    min     
-----+------------
   1 | 2014-01-01
   2 | 2014-01-04
   3 | 2014-01-05
   4 | 2014-01-02
   5 | 2014-01-01
   8 | 2014-01-02
   9 | 2014-01-01
  10 | 2014-01-03
  11 | 2014-01-01
  12 | 2014-01-02
(10 rows)
```

Пользователи 6 и 7, которые есть в таблице `user`, но которых нет в таблице `log`, сюда не попали,
так как их визитов не зарегистрировано.

```
dgolub=> update prj1.user
  set first_visit = fs.min
from first_seen as fs
where fs.uid = prj1.user.uid;
UPDATE 3637

dgolub=> select * from prj1.user limit 12;
 uid |    source    |   region   | cost | first_visit | start_mon | start_week 
-----+--------------+------------+------+-------------+-----------+------------
  51 | cpc_direct   | orel       |  438 | 2014-01-03  |           |           
  52 | smm          | spb        |  452 | 2014-01-01  |           |           
  53 | cpc_adwords  | spb        |  475 | 2014-01-01  |           |           
  54 | smm          | spb        |  245 | 2014-01-01  |           |           
  56 | cpc_adwords  | volgograd  |  365 | 2014-01-02  |           |           
   6 | smm          | moscow     |  414 |             |           |           
   7 | cpc_adwords  | moscow     |  258 |             |           |           
  57 | smm          | volgograd  |  430 | 2014-01-02  |           |           
  58 | cpc_direct   | volgograd  |  473 | 2014-01-02  |           |           
  59 | cpc_direct   | vladimir   |  373 | 2014-01-01  |           |           
  60 | smm          | vladimir   |  470 | 2014-01-01  |           |           
  61 | seo          | vladimir   |  409 | 2014-01-01  |           |           
(12 rows)
```

Номера месяцев и недель заполняю аналогично таблице лога.

```
dgolub=> update prj1.user set start_mon=date_part('month',first_visit);
UPDATE 3910

dgolub=> update prj1.user set start_week=date_part('week',first_visit);
UPDATE 3910
```

Немного произвольно я считаю, что тот месяц, когда пользователь первый раз посетил сайт,
и есть месяц его привлечения. Стоимость привлечания я отношу именно сюда.

Тогда стоимость привлечения по месяцам:

```
select sum(cost) from prj1.user where start_mon = 1;
```

## Первая покупка

В ходе когортного анализа я столкнулся с возможностью двойного учёта покупателей в разные недели
и решил сделать таблицу, где будут учтены первые покупки для каждого покупателя.

```
create table prj1.first_buy as 
    select uid, min(date) as fpdate, min(week) as fpweek 
    from prj1.log 
    where sum is not null 
    group by uid 
    order by min(date);
```

Проверяю, что создалось:

```
dgolub=> select * from prj1.first_buy order by uid limit 10;
 uid |   fpdate   | fpweek 
-----+------------+--------
   1 | 2014-01-01 |      1
   2 | 2014-01-04 |      1
   4 | 2014-01-02 |      1
   5 | 2014-01-04 |      1
   8 | 2014-01-02 |      1
   9 | 2014-01-02 |      1
  10 | 2014-01-07 |      2
  11 | 2014-01-08 |      2
  12 | 2014-01-03 |      1
  13 | 2014-01-31 |      5
```

Проверил, хорошо ли объединяются все три таблицы. Несколько строк с покупателями:

```
dgolub=> select * from prj1.log join prj1.user using (uid) join prj1.first_buy using (uid) order by uid limit 10;

 uid |    date    | event_type | sum  | month | week |    source    |   region   | cost | first_visit | start_mon | start_week |   fpdate   | fpweek 
-----+------------+------------+------+-------+------+--------------+------------+------+-------------+-----------+------------+------------+--------
   1 | 2014-01-04 | visit      |      |     1 |    1 | seo          | vladimir   |  321 | 2014-01-01  |         1 |          1 | 2014-01-01 |      1
   1 | 2014-01-02 | visit      |      |     1 |    1 | seo          | vladimir   |  321 | 2014-01-01  |         1 |          1 | 2014-01-01 |      1
   1 | 2014-01-01 | visit      |      |     1 |    1 | seo          | vladimir   |  321 | 2014-01-01  |         1 |          1 | 2014-01-01 |      1
   1 | 2014-01-01 | purchase   | 1649 |     1 |    1 | seo          | vladimir   |  321 | 2014-01-01  |         1 |          1 | 2014-01-01 |      1
   1 | 2014-01-05 | visit      |      |     1 |    1 | seo          | vladimir   |  321 | 2014-01-01  |         1 |          1 | 2014-01-01 |      1
   1 | 2014-01-02 | visit      |      |     1 |    1 | seo          | vladimir   |  321 | 2014-01-01  |         1 |          1 | 2014-01-01 |      1
   1 | 2014-01-02 | visit      |      |     1 |    1 | seo          | vladimir   |  321 | 2014-01-01  |         1 |          1 | 2014-01-01 |      1
   1 | 2014-01-07 | visit      |      |     1 |    2 | seo          | vladimir   |  321 | 2014-01-01  |         1 |          1 | 2014-01-01 |      1
   1 | 2014-01-03 | visit      |      |     1 |    1 | seo          | vladimir   |  321 | 2014-01-01  |         1 |          1 | 2014-01-01 |      1
   1 | 2014-01-10 | visit      |      |     1 |    2 | seo          | vladimir   |  321 | 2014-01-01  |         1 |          1 | 2014-01-01 |      1
```

## Выводы и заметки по поводу преобразования данных

- Конечно, изменение существующих и создание дополнительных таблиц оказалось возможным только потому, 
что база работает у меня локально на машине и я её администратор. В случае большой базы это невозможно.

- Вместо добавления полей в существующую таблицу `user`, было правильнее сделать отдельную таблицу `first_visit`, аналогичную `first_buy`.
А вот преобразование 'log' (добавление месяца и недели первой покупки) было правильным, только для наших нужд месяц не нужен,
достаточно было недели.

- Есть возможность использовать View вместо добавления таблиц и колонок — база небольшая, дополнительные расходы ресурсов невелики.


# Анализ данных

## Когортный анализ

Начало отсчёта 1 января 2014, окончание 5 марта 2014. 10 недель (1-10)

### Когорта 1 недели.

Кол-во поcетителей: 381.

```
select count(distinct uid) from prj1.user where start_week=1;
```

Кол-во покупателей за время жизни когорты: 267.

```
select count(distinct l.uid)
from 
        prj1.log as l 
        left join 
        prj1.user as u 
        on l.uid=u.uid 
where 
        u.start_week=1 
        and 
        l.sum is not null;
```

Получается конверсия за всё время жизни когорты примерно 0.701 или 70.1%.

Количество сделок на одного пользователя из этой когорты легко получается из предыдущего запроса:

```
select count(l.uid) 
from prj1.log as l left join prj1.user as u on l.uid=u.uid 
where u.start_week=1 and l.sum is not null;
```

Получается 701, что даёт APC в 2.6255.

Считаем сумму всех сделок и средний чек.  Тут я решил, что мне `left join` не нужен, и достаточно
`natural join`.

```
select sum(sum) from prj1.log as l natural join prj1.user as u where u.start_week=1 and l.sum is not null;
```

Получается сумма сделок 628578 и средний чек round(628578.0/701,2) = 896.69.

С учётом этих данных валовая прибыль на клиента (Average gross profit per customer) будет 2354.23 и
ARPU при такой высокой конверсии достигнет 1649.82.

Расходная часть: суммарные расходы на привлечение пользователей 1 когорты и стоимость привлечения посетителя:

```
dgolub=> select sum(cost) from prj1.user where start_week=1;
  sum   
--------
 134820
(1 row)

dgolub=> select sum(cost)/count(uid) as cpa from prj1.user where start_week=1;
       cpa
------------------
 353.858267716535
```

### 2  и последующий недели

Мне надоело запускать команды руками снова и снова, и я пошёл двумя путями: группировки в SQL и запросы к БД из внешней программы
на Python.  Например, количество посетителей по всем когортам получается запросом:

```
dgolub=> select start_week,count(uid) from prj1.user where start_week is not null group by start_week order by start_week;
 start_week | count 
------------+-------
          1 |   381
          2 |   476
          3 |   340
          4 |   347
          5 |   495
          6 |   548
          7 |   302
          8 |   403
          9 |   329
         10 |    16
(10 rows)
```

### Количество покупателей по когортам

```
select u.start_week,count(distinct u.uid)
from 
	prj1.log as l natural join prj1.user as u 
where 
	u.start_week is not null and
	l.sum is not null and
	l.sum > 0 
group by u.start_week 
order by u.start_week;
```

То же, с разбивкой по неделям покупки:

```
select u.start_week, l.week,count(distinct u.uid)
from 
	prj1.log as l natural join prj1.user as u 
where 
	u.start_week is not null and
	l.sum is not null and
	l.sum > 0 
group by u.start_week, l.week 
order by u.start_week, l.week;
```

Средний чек:

```
select u.start_week, avg(l.sum) as avp 
from
	prj1.log as l natural join prj1.user as u 
where l.sum is not null
group by u.start_week
order by start_week;

start_week |       avp        
------------+------------------
          1 | 896.687589158345
          2 |  852.65548098434
          3 | 886.500851788756
          4 | 865.677265500795
          5 | 893.192401960784
          6 | 860.355408388521
          7 | 867.108910891089
          8 | 861.261450381679
          9 |  866.37216828479
         10 | 852.571428571429

```

Количество посетителей, расходы на них, стоимость 1 посетителя:

```
dgolub=> select start_week,count(distinct uid) as ua, sum(cost) as ac, sum(cost)/count(distinct uid) as cpa from prj1.user group by start_week order by start_week;
 start_week | ua  |   ac   |       cpa        
------------+-----+--------+------------------
          1 | 381 | 134820 | 353.858267716535
          2 | 476 | 165191 | 347.039915966387
          3 | 340 | 120432 | 354.211764705882
          4 | 347 | 121212 | 349.314121037464
          5 | 495 | 175685 | 354.919191919192
          6 | 548 | 189669 | 346.111313868613
          7 | 302 | 106530 | 352.748344370861
          8 | 403 | 138506 | 343.687344913151
          9 | 329 | 114109 | 346.835866261398
         10 |  16 |   5842 |          365.125
            | 273 |  94505 | 346.172161172161
(11 rows)
```

Заполнив таблицу с помощью Python-овской программы, столкнулся с двойным учётом покупателей. Видимо, нужно все покупки пользвателя относить
к той неделе, когда он купил что-нибудь в первый раз. 

Для облегчения себе жизни создал таблицу с первыми покупками пользователей.

Тогда список пользователей из январской когорты, у которых первая покупка тоже пришлась на январь, выдаются так:

```
dgolub=> select count(distinct uid)
from prj1.log as l
inner join
prj1.user as u on l.uid = u.uid
inner join
prj1.first_buy as f on l.uid = f.uid
limit 10;
```

```
select count(distinct u.uid) from prj1.log as l left join prj1.user as u on l.uid = u.uid left join prj1.first_buy as b on l.uid = b.uid where sum is not null and u.start_week=1 and b.fpweek=1 and week=2;
```

TIP: можно выставить использование схемы по умолчанию и далее пользоваться короткими названиями таблиц.

```
SET search_path TO prj1;

dgolub=> \d
          List of relations
 Schema |   Name    | Type  | Owner  
--------+-----------+-------+--------
 prj1   | first_buy | table | dgolub
 prj1   | log       | table | dgolub
 prj1   | user      | table | dgolub
```

Разбивка покупателей по когортам и неделям, в которую была совершена первая покупка:

```
select u.start_week, b.fpweek, count(distinct u.uid) from prj1.log as l left join prj1.user as u on l.uid = u.uid left join prj1.first_buy as b on l.uid = b.uid where sum is not null group by u.start_week,b.fpweek order by u.start_week,b.fpweek;

start_week | fpweek | count 
------------+--------+-------
          1 |      1 |   188
          1 |      2 |    58
          1 |      3 |    13
          1 |      4 |     1
...
          8 |     10 |     7
          9 |      9 |   161
          9 |     10 |    30
         10 |     10 |     7
```

### Немного программирования

Вводить команды (даже копированием из текстового файла) снова и снова лень, да и в конце концов это работа
для компьютера.  Так что я запрограммировал всё, что мне нужно, в Python с использованием модуля `psycopg2`.
Программа строит и выводит дата-фреймы, которые я вставляю в табличный процессор копи-пастом.  Неизящно,
но разбираться, как записывать данные в файлы Excel или Calc, я решил как-нибудь потом.

Программа: `cohort_analysis.py`

### Составление таблицы

За исходную таблицу для когортного анализа взял таблицу Даниила Ханина (доступна по ссылке из его видео в Youtube),
минимально модифицировал её для использования недель вместо месяцев.

## Анализ по городам и источникам посетителей

Основная часть работы была проведена при составлении программы, которая соединяется с базой, делает в неё запросы и составляет
pandas-овские Data Frames. Программа `ue_by_city.py`

Программа выводит блоки данных, которые нужно просто вставить в электронную таблицу или отчёт:

 - Глобальная юнит-экономика: APC, AVP, UA, CPA, C1, ARPC, ARPU, ROMI. Остальные блоки будут использовать эти же параметры
   в этой же последовательности, но будут выполнять срезы по той или иной группе пользователей
   
 - UE по источникам привлечения пользователей
 - UE по регионам
 - Таблица по источникам и регионам (в Pandas использован составной индекс): источник, регион, APC, AVP, ...

Собственно, на этом можно было закончить и остальные срезы сделать с помощью сводных таблиц в Google Sheets или 
LibreOffice Calc.  Но имея под рукой всю функциональность Pandas, зачем пользоваться сводными таблицами? Поэтому
все срезы тоже выведены из Pandas:

 - UE по источникам привлечения (4 таблицы, по одной на источник, в каждой 6 строк по регионам)
 - UE по регионам (6 таблиц, по одной на регион, в каждой 4 строки по источникам)
 - Индикаторы UE (по таблице на каждый параметр: APC, UA, ..., ROMI). Строки таблицы — источники, колонки — регионы.

Всё выводится в CSV для вставки в табличный процессор.  В будущем нужно будет освоить выдачу в XLS/ODS.

## Почему я не провожу анализ по когортам, городам и источникам?

Можно было бы внести в куб данных дополнительное измерение: когорты.  Но количество пользователей невелико, и я
опасаюсь, что из когорты в 500 пользователей в ячейке "когорта/источник/регион" окажется в среднем два десятка,
а это не то количество, на котором можно считать статистику.

# Проверка на фокус-маркетологе :)

14.10 обсудили получающиеся таблицы с нашим внутрифирменным маркетологом, основные результаты:
 - Смотреть на то, что даёт максимальный доход.  Это SEO и Google Ads,  из городов - Мск, Питер, Екб. Волгоград
 - Продвигать SEO в Мск и Спб, Директ в СПб
 - Сделать разрез параметров UE по методам, 1 табличка на регион, сортировать по ROMI (сделано)
 - Сделать аналогичный разрез по регионам, 1 табличка на метод, сортировать по ROMI (сделано)
 - Топ источников по регионам, смотрим ARPC.
